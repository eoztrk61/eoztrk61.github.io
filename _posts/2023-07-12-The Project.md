---
layout: post
title: The Project
categories: [category 1, category 2]
---

# The Text Analyse of the Ceres Website

_The final version of the project is given in this post._

The contents of the news in the news section of the website of the Centre for the Religious Studies at Ruhr University were analysed by text analysis.
## **_Part 1: WebScraping via OpenRefine_**
Firstly, I obtained the data required for the project by webscraping and edited it to make it suitable for text analysis.

**Step 1:**   Getting the links of 52 pages in the _News_ section

![Step1](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/Step_1.jpg?raw=true)


**Step 2:**   Access data on each page

![Step2](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/Step_2.jpg?raw=true)


**Step 3:**   The postlinks of the posts are extracted from the data obtained

![Step3](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/Step_3.jpg?raw=true)


**Step 4:**   Postlinks are splitted

![Step4](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/Step_4.jpg?raw=true)


**Step 5:**   Real links of the posts are created 

![Step5](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/Step_5.jpg?raw=true)


**Step 6:**   The page source of real links is reached

![Step6](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/Step_6.jpg?raw=true)


**Step 7:**   Post texts are obtained from the page source

![Step7](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/Step_7.jpg?raw=true)


**Step 8:**   Slugs are taken from the real links of each post 

![Step8](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/Step_8.jpg?raw=true)


**Step 9:**   Date and time column for posts are added  

![Step9](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/Step_9.jpg?raw=true)


**Step 10:**   Redundant columns are removed 

![Step10](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/Step_10.jpg?raw=true)


**Step 11:**   files are created and downloaded

![Step11](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/Step_11.jpg?raw=true)


## **_Part 2: Text Analyse via Voyant Tools_** 
Scraped data is downloaded as xls file and text.
The text Analysis, after uploading the text documents to Voyant tools is as follows:

![Text1](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/Text-1.jpg?raw=true)

To analyse only certain words, I used the "Whitelist" option:

![text2](https://github.com/eoztrk61/eoztrk61.github.io/blob/main/assets/text-2.jpg?raw=true)

In this project, in which I tried to analyse the use of the names of major religions in the "News" section of the CERES website, I felt the lack of participation in the "Text Analysis" course. 
